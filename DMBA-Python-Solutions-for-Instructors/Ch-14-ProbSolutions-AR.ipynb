{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 14: Association Rules and Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> (c) 2019-2020 Galit Shmueli, Peter C. Bruce, Peter Gedeck \n",
    ">\n",
    "> _Data Mining for Business Analytics: Concepts, Techniques, and Applications in Python_ (First Edition) \n",
    "> Galit Shmueli, Peter C. Bruce, Peter Gedeck, and Nitin R. Patel. 2019.\n",
    ">\n",
    "> Date: 2020-03-08\n",
    ">\n",
    "> Python Version: 3.8.2\n",
    "> Jupyter Notebook Version: 5.6.1\n",
    ">\n",
    "> Packages:\n",
    ">   - mlxtend: 0.17.2\n",
    ">   - numpy: 1.18.1\n",
    ">   - pandas: 1.0.1\n",
    ">   - scipy: 1.4.1\n",
    ">   - scikit-learn: 0.22.2\n",
    ">   - scikit-surprise: 1.1.0\n",
    ">\n",
    "> The assistance from Mr. Kuber Deokar and Ms. Anuja Kulkarni in preparing these solutions is gratefully acknowledged.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages for this chapter\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import KNNBasic\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working directory:\n",
    "#\n",
    "# We assume that data are kept in the same directory as the notebook. If you keep your \n",
    "# data in a different folder, replace the argument of the `Path`\n",
    "DATA = Path('.')\n",
    "# and then load data using \n",
    "#\n",
    "# pd.read_csv(DATA / ‘filename.csv’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 14.1: Satellite Radio Customers\n",
    "An analyst at a subscription-based\n",
    "satellite radio company has been given a sample of data from their\n",
    "customer database, with the goal of finding groups of customers who\n",
    "are associated with one another. The data consist of company data,\n",
    "together with purchased demographic data that are mapped to the\n",
    "company data (see Table). The analyst\n",
    "decides to apply association rules to learn more about the\n",
    "associations between customers. Comment on this approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 14.1\n",
    "Association rules is not the correct approach. It determines associations among items listed in the columns (demographic and other descriptor variables in this database), not associations between rows (customers in this database). Cluster analysis would be more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 14.2: Identifying Course Combinations\n",
    "The Institute for Statistics Education at Statistics.com offers online courses in statistics and analytics, and is seeking information that will help in packaging and sequencing courses.  Consider the data in the file _CourseTopics.csv_, the first few rows of which are shown in the Table. These data are for purchases of online statistics courses at Statistics.com. Each row represents the courses attended by a single customer.\n",
    "The firm wishes to assess alternative sequencings and bundling of courses. Use association rules to analyze these data, and interpret several of the resulting rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intro</th>\n",
       "      <th>DataMining</th>\n",
       "      <th>Survey</th>\n",
       "      <th>Cat Data</th>\n",
       "      <th>Regression</th>\n",
       "      <th>Forecast</th>\n",
       "      <th>DOE</th>\n",
       "      <th>SW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Intro  DataMining  Survey  Cat Data  Regression  Forecast  DOE  SW\n",
       "0      1           1       0         0           0         0    0   0\n",
       "1      0           0       1         0           0         0    0   0\n",
       "2      0           1       0         1           1         0    0   1\n",
       "3      1           0       0         0           0         0    0   0\n",
       "4      1           1       0         0           0         0    0   0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA / 'CourseTopics.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 14.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                antecedents             consequents   support  confidence  \\\n",
      "316            (Intro, DOE)        (SW, Regression)  0.019178    0.411765   \n",
      "321        (SW, Regression)            (Intro, DOE)  0.019178    0.350000   \n",
      "319       (Regression, DOE)             (Intro, SW)  0.019178    0.636364   \n",
      "318             (Intro, SW)       (Regression, DOE)  0.019178    0.200000   \n",
      "249     (Intro, DataMining)  (Forecast, Regression)  0.013699    0.250000   \n",
      "248  (Forecast, Regression)     (Intro, DataMining)  0.013699    0.357143   \n",
      "\n",
      "         lift  leverage  \n",
      "316  7.514706  0.016626  \n",
      "321  7.514706  0.016626  \n",
      "319  6.636364  0.016288  \n",
      "318  6.636364  0.016288  \n",
      "249  6.517857  0.011597  \n",
      "248  6.517857  0.011597  \n"
     ]
    }
   ],
   "source": [
    "# create frequent itemsets\n",
    "itemsets = apriori(df, min_support=0.01, use_colnames=True)\n",
    "\n",
    "# and convert into rules\n",
    "rules = association_rules(itemsets, metric='confidence', min_threshold=0.1)\n",
    "rules.sort_values(by=['lift'], ascending=False).head(6)\n",
    "\n",
    "print(rules.sort_values(by=['lift'], ascending=False)\n",
    "      .drop(columns=['antecedent support', 'consequent support', 'conviction'])\n",
    "      .head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>(Forecast, Intro, Regression)</td>\n",
       "      <td>(DataMining)</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>4.010989</td>\n",
       "      <td>0.010283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>(Intro, Survey, DOE)</td>\n",
       "      <td>(Cat Data)</td>\n",
       "      <td>0.010959</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>3.842105</td>\n",
       "      <td>0.008107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>(Intro, DataMining, Cat Data)</td>\n",
       "      <td>(Regression)</td>\n",
       "      <td>0.016438</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>3.601974</td>\n",
       "      <td>0.011875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>(Intro, Survey, Cat Data)</td>\n",
       "      <td>(Forecast)</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.578431</td>\n",
       "      <td>0.009871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>(Intro, DataMining, Regression)</td>\n",
       "      <td>(Forecast)</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.578431</td>\n",
       "      <td>0.009871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>(Intro, Regression, DOE)</td>\n",
       "      <td>(SW)</td>\n",
       "      <td>0.019178</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>3.504801</td>\n",
       "      <td>0.013706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         antecedents   consequents   support  confidence  \\\n",
       "243    (Forecast, Intro, Regression)  (DataMining)  0.013699    0.714286   \n",
       "262             (Intro, Survey, DOE)    (Cat Data)  0.010959    0.800000   \n",
       "233    (Intro, DataMining, Cat Data)  (Regression)  0.016438    0.750000   \n",
       "255        (Intro, Survey, Cat Data)    (Forecast)  0.013699    0.500000   \n",
       "245  (Intro, DataMining, Regression)    (Forecast)  0.013699    0.500000   \n",
       "312         (Intro, Regression, DOE)          (SW)  0.019178    0.777778   \n",
       "\n",
       "         lift  leverage  \n",
       "243  4.010989  0.010283  \n",
       "262  3.842105  0.008107  \n",
       "233  3.601974  0.011875  \n",
       "255  3.578431  0.009871  \n",
       "245  3.578431  0.009871  \n",
       "312  3.504801  0.013706  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter rules to have only one consequent\n",
    "single_rules = rules[[len(c) == 1 for c in rules.consequents]]\n",
    "(single_rules.sort_values(by=['lift'], ascending=False)\n",
    "      .drop(columns=['antecedent support', 'consequent support', 'conviction'])\n",
    "      .head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting some rules:\n",
    "\n",
    "- The first rule is \"If Intro, Regression and Forecasting are taken, Data Mining is also taken.\" It has confidence of 71.4%, and a lift of 4.\n",
    "- The second rule is \"If Intro, Survey and DOE are taken, Categorical Data is also taken.\" It has confidence of 80% and lift of 3.84.\n",
    "\n",
    "The support (a U c) for all rules is very low. under 4%. This means that the \n",
    "applicability of these rules is not great, and also that the chances are \n",
    "greater that we are not picking up true associations that will persist into \n",
    "the future -- just random noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 14.3: Recommending Courses\n",
    "We again consider the data in _CourseTopics.csv_ describing course purchases at Statistics.com (see Problem 14.2 and data sample in Table). We want to provide a course recommendation to a student who purchased the Regression and Forecast courses. Apply user-based collaborative filtering to the data. All recommendations will be 1. Explain why this happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 14.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intro</th>\n",
       "      <th>DataMining</th>\n",
       "      <th>Survey</th>\n",
       "      <th>Cat Data</th>\n",
       "      <th>Regression</th>\n",
       "      <th>Forecast</th>\n",
       "      <th>DOE</th>\n",
       "      <th>SW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Intro  DataMining  Survey  Cat Data  Regression  Forecast  DOE  SW\n",
       "0      1           1       0         0           0         0    0   0\n",
       "1      0           0       1         0           0         0    0   0\n",
       "2      0           1       0         1           1         0    0   1\n",
       "3      1           0       0         0           0         0    0   0\n",
       "4      1           1       0         0           0         0    0   0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course_df = pd.read_csv(DATA / 'Coursetopics.csv')\n",
    "course_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intro</th>\n",
       "      <th>DataMining</th>\n",
       "      <th>Survey</th>\n",
       "      <th>Cat Data</th>\n",
       "      <th>Regression</th>\n",
       "      <th>Forecast</th>\n",
       "      <th>DOE</th>\n",
       "      <th>SW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Intro  DataMining  Survey  Cat Data  Regression  Forecast  DOE  SW\n",
       "0      1           1       1         1           1         1    1   1\n",
       "1      1           1       1         1           1         1    1   1\n",
       "2      1           1       1         1           1         1    1   1\n",
       "3      1           1       1         1           1         1    1   1\n",
       "4      1           1       1         1           1         1    1   1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = []\n",
    "for customer, row in course_df.iterrows():\n",
    "    for course, value in row.iteritems():\n",
    "        if value==0: continue\n",
    "        ratings.append([customer, course, value])\n",
    "ratings = pd.DataFrame(ratings, columns=['customer', 'course', 'rating'])\n",
    "\n",
    "reader = Reader(rating_scale=(1, 1))\n",
    "data = Dataset.load_from_df(ratings, reader)\n",
    "trainset = data.build_full_trainset()\n",
    "sim_options = {'name': 'cosine', 'user_based': False}  # compute cosine similarities between users\n",
    "algo = KNNBasic(sim_options=sim_options)\n",
    "algo.fit(trainset)\n",
    "\n",
    "predictions = []\n",
    "for user in course_df.index:\n",
    "    predictions.append([algo.predict(user, course).est for course in course_df])\n",
    "predictions = pd.DataFrame(predictions, columns=course_df.columns)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting predictions are all 1. This is because the input is not a rating matrix but a binary one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 14.4: Cosmetics Purchases\n",
    "The data and rules shown in the book are based on a subset of a dataset on cosmetic purchases (_Cosmetics.csv_) at a large chain drugstore. The store wants to analyze associations among purchases of these items for purposes of point-of-sale display, guidance to\n",
    "sales personnel in promoting cross-sales, and guidance for piloting an\n",
    "eventual time-of-purchase electronic recommender system to boost\n",
    "cross-sales. Consider first only the data shown in Table, given in binary matrix form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bag</th>\n",
       "      <th>Blush</th>\n",
       "      <th>Nail Polish</th>\n",
       "      <th>Brushes</th>\n",
       "      <th>Concealer</th>\n",
       "      <th>Eyebrow Pencils</th>\n",
       "      <th>Bronzer</th>\n",
       "      <th>Lip liner</th>\n",
       "      <th>Mascara</th>\n",
       "      <th>Eye shadow</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>Lip Gloss</th>\n",
       "      <th>Lipstick</th>\n",
       "      <th>Eyeliner</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trans.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Bag  Blush  Nail Polish  Brushes  Concealer  Eyebrow Pencils  \\\n",
       "Trans.                                                                  \n",
       "1          0      1            1        1          1                0   \n",
       "2          0      0            1        0          1                0   \n",
       "3          0      1            0        0          1                1   \n",
       "4          0      0            1        1          1                0   \n",
       "5          0      1            0        0          1                0   \n",
       "\n",
       "         Bronzer  Lip liner  Mascara  Eye shadow  Foundation  Lip Gloss  \\\n",
       "Trans.                                                                    \n",
       "1              1          1        1           0           0          0   \n",
       "2              1          1        0           0           1          1   \n",
       "3              1          1        1           1           1          1   \n",
       "4              1          0        0           0           1          0   \n",
       "5              1          1        1           1           0          1   \n",
       "\n",
       "         Lipstick  Eyeliner  \n",
       "Trans.                       \n",
       "1               0         1  \n",
       "2               0         0  \n",
       "3               1         0  \n",
       "4               0         1  \n",
       "5               1         0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosmetics_df = pd.read_csv(DATA / 'Cosmetics.csv', index_col='Trans. ')\n",
    "cosmetics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 14.4.a\n",
    "Select several values in the matrix and explain their meaning.\n",
    "\n",
    "The \"0\" in the first row, first column under \"bag\" indicates that, in the \n",
    "first transaction (i.e. the first row), no bag was purchased. The \"1\" to its \n",
    "right indicates that blush was purchased in that first transaction.\n",
    "\n",
    "\n",
    "## Solution 14.4.b\n",
    "Consider the results of the association rules analysis shown in the book.\n",
    "\n",
    "### Solution 14.4.b.i\n",
    "For the first row, explain the `confidence` output and how it is calculated.\n",
    "\n",
    "If Blush, Concealer, Mascara, Eye.shadow, Lipstick were purchased, 30% of the \n",
    "time Eyebrow.Pencils were also purchased. The calculation is:\n",
    "\n",
    "> 100 * (# transactions with Blush + Concealer + Mascara + Eye.shadow + Lipstick) / (# transactions with Eyebrow.Pencils)\n",
    "\n",
    "\n",
    "### Solution 14.4.b.ii\n",
    "For the first row, explain the `support` output and how it is calculated.\n",
    "\n",
    "The Support of 0.013 means there were 13 transactions in which \n",
    "> Blush + Concealer + Mascara + Eye.shadow + Lipstick + Eyebrow.Pencils \n",
    "\n",
    "were purchased.\n",
    "\n",
    "\n",
    "### Solution 14.4.b.iii\n",
    "For the first row, explain the `lift` and how it is calculated.\n",
    "\n",
    "Lift Ratio = 7.19 means we are 7.19 times more likely to find a transaction \n",
    "with Eyebrow.Pencils IF we look only in those transactions where \n",
    "> Blush + Concealer + Mascara + Eye.shadow + Lipstick \n",
    "\n",
    "are purchased, compared to searching randomly in all transactions.\n",
    "The calculation:\n",
    "\n",
    "> ((# trans with Eyebrow.Pencils + Blush + Concealer + Mascara + Eye.shadow + Lipstick)/\n",
    "   (# trans with Blush + Concealer + Mascara + Eye.shadow + Lipstick)) / \n",
    "  ((# trans with Eyebrow.Pencils) / (all transactions))\n",
    "\n",
    "\n",
    "### Solution 14.4.b.iv\n",
    "For the first row, explain the rule that is represented there in words.\n",
    "\n",
    "The rule is \"If a transaction includes Blush + Concealer + Mascara + Eye.shadow + Lipstick, \n",
    "it will also include Eyebrow.Pencils.\"  \n",
    "\n",
    "If we are searching for transactions with Eyebrow.Pencils, limiting our\n",
    "search to transactions with Blush + Concealer + Mascara + Eye.shadow + Lipstick will \n",
    "increase our probability of success by a factor of 7.19.\n",
    "\n",
    "## Solution 14.4.c\n",
    "Now, use the complete dataset on the cosmetics purchases (in the file _Cosmetics.csv_). Using Python, apply association rules to these data (for _apriori_ use `min_support=0.1` and `use_colnames=True`, for _association_rules_ use default parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Brushes)</td>\n",
       "      <td>(Nail Polish)</td>\n",
       "      <td>0.149</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.107280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(Concealer, Eye shadow, Blush)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.959677</td>\n",
       "      <td>2.688172</td>\n",
       "      <td>0.074732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Eye shadow, Blush)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>2.601040</td>\n",
       "      <td>0.104026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Eye shadow, Nail Polish)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.908397</td>\n",
       "      <td>2.544529</td>\n",
       "      <td>0.072233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(Eye shadow, Concealer)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.890547</td>\n",
       "      <td>2.494530</td>\n",
       "      <td>0.107243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(Eye shadow, Bronzer)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.879433</td>\n",
       "      <td>2.463397</td>\n",
       "      <td>0.073663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(Eye shadow, Concealer, Eyeliner)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>2.456367</td>\n",
       "      <td>0.067590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Mascara, Blush)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.918478</td>\n",
       "      <td>2.410704</td>\n",
       "      <td>0.098896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(Lipstick, Eye shadow)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>2.388552</td>\n",
       "      <td>0.063947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(Lipstick, Mascara)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>2.386065</td>\n",
       "      <td>0.063899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(Concealer, Mascara, Blush)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.908397</td>\n",
       "      <td>2.384244</td>\n",
       "      <td>0.069089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(Bronzer, Mascara)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>2.375615</td>\n",
       "      <td>0.071803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.842520</td>\n",
       "      <td>2.359999</td>\n",
       "      <td>0.184983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.899160</td>\n",
       "      <td>2.359999</td>\n",
       "      <td>0.184983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Nail Polish, Mascara)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.888060</td>\n",
       "      <td>2.330865</td>\n",
       "      <td>0.067946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(Eye shadow, Eyeliner)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.829670</td>\n",
       "      <td>2.324007</td>\n",
       "      <td>0.086026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(Concealer, Mascara)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.877451</td>\n",
       "      <td>2.303021</td>\n",
       "      <td>0.101276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(Mascara, Lip Gloss)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.872928</td>\n",
       "      <td>2.291150</td>\n",
       "      <td>0.089039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(Mascara, Foundation)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.864583</td>\n",
       "      <td>2.269248</td>\n",
       "      <td>0.092848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(Mascara, Eyeliner)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.862857</td>\n",
       "      <td>2.264717</td>\n",
       "      <td>0.084325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          antecedents    consequents  support  confidence  \\\n",
       "0                           (Brushes)  (Nail Polish)    0.149    1.000000   \n",
       "21     (Concealer, Eye shadow, Blush)      (Mascara)    0.119    0.959677   \n",
       "4                 (Eye shadow, Blush)      (Mascara)    0.169    0.928571   \n",
       "6           (Eye shadow, Nail Polish)      (Mascara)    0.119    0.908397   \n",
       "11            (Eye shadow, Concealer)      (Mascara)    0.179    0.890547   \n",
       "13              (Eye shadow, Bronzer)      (Mascara)    0.124    0.879433   \n",
       "23  (Eye shadow, Concealer, Eyeliner)      (Mascara)    0.114    0.876923   \n",
       "5                    (Mascara, Blush)   (Eye shadow)    0.169    0.918478   \n",
       "17             (Lipstick, Eye shadow)      (Mascara)    0.110    0.852713   \n",
       "18                (Lipstick, Mascara)   (Eye shadow)    0.110    0.909091   \n",
       "22        (Concealer, Mascara, Blush)   (Eye shadow)    0.119    0.908397   \n",
       "14                 (Bronzer, Mascara)   (Eye shadow)    0.124    0.905109   \n",
       "1                        (Eye shadow)      (Mascara)    0.321    0.842520   \n",
       "2                           (Mascara)   (Eye shadow)    0.321    0.899160   \n",
       "7              (Nail Polish, Mascara)   (Eye shadow)    0.119    0.888060   \n",
       "19             (Eye shadow, Eyeliner)      (Mascara)    0.151    0.829670   \n",
       "12               (Concealer, Mascara)   (Eye shadow)    0.179    0.877451   \n",
       "16               (Mascara, Lip Gloss)   (Eye shadow)    0.158    0.872928   \n",
       "15              (Mascara, Foundation)   (Eye shadow)    0.166    0.864583   \n",
       "20                (Mascara, Eyeliner)   (Eye shadow)    0.151    0.862857   \n",
       "\n",
       "        lift  leverage  \n",
       "0   3.571429  0.107280  \n",
       "21  2.688172  0.074732  \n",
       "4   2.601040  0.104026  \n",
       "6   2.544529  0.072233  \n",
       "11  2.494530  0.107243  \n",
       "13  2.463397  0.073663  \n",
       "23  2.456367  0.067590  \n",
       "5   2.410704  0.098896  \n",
       "17  2.388552  0.063947  \n",
       "18  2.386065  0.063899  \n",
       "22  2.384244  0.069089  \n",
       "14  2.375615  0.071803  \n",
       "1   2.359999  0.184983  \n",
       "2   2.359999  0.184983  \n",
       "7   2.330865  0.067946  \n",
       "19  2.324007  0.086026  \n",
       "12  2.303021  0.101276  \n",
       "16  2.291150  0.089039  \n",
       "15  2.269248  0.092848  \n",
       "20  2.264717  0.084325  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequentItemsets = apriori(cosmetics_df, min_support=0.1, use_colnames=True)\n",
    "\n",
    "rules = association_rules(frequentItemsets)\n",
    "\n",
    "(rules.sort_values(by=['lift'], ascending=False).head(20)\n",
    "     .drop(columns=['antecedent support', 'consequent support', 'conviction']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 14.4.c.i\n",
    "Interpret the first three rules in the output in words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Brushes)</td>\n",
       "      <td>(Nail Polish)</td>\n",
       "      <td>0.149</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.107280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(Concealer, Eye shadow, Blush)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.959677</td>\n",
       "      <td>2.688172</td>\n",
       "      <td>0.074732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Eye shadow, Blush)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>2.601040</td>\n",
       "      <td>0.104026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       antecedents    consequents  support  confidence  \\\n",
       "0                        (Brushes)  (Nail Polish)    0.149    1.000000   \n",
       "21  (Concealer, Eye shadow, Blush)      (Mascara)    0.119    0.959677   \n",
       "4              (Eye shadow, Blush)      (Mascara)    0.169    0.928571   \n",
       "\n",
       "        lift  leverage  \n",
       "0   3.571429  0.107280  \n",
       "21  2.688172  0.074732  \n",
       "4   2.601040  0.104026  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rules.sort_values(by=['lift'], ascending=False).head(3)\n",
    "     .drop(columns=['antecedent support', 'consequent support', 'conviction']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First row: If brushes are purchased, nail polish is purchased. This rule has 100% confidence -- purchasing a brush guarantees purchase of nail polish. It has lift of 3.6, and support of about 15% (149 transactions out of 1000) for the two items together.\n",
    "\n",
    "- Second row: if nail Blush, Concealer and Eye.shadow are purchased, Mascara is purchased. This rule has confidence of 96% -- if Blush, Concealer and Eye.shadow are purchased, Mascara is 96% likely to be purchased as well. It has lift of 3.571, and support of about 12%.\n",
    "\n",
    "- Third row: If Blush and Eye.shadow are purchased, Mascara is also purchased. This rule has confidence of 93%, lift of 2.6, and support of about 17%.\n",
    "\n",
    "\n",
    "### Solution 14.4.c.ii\n",
    "Reviewing the first couple of dozen rules, comment on their redundancy and how you would assess their utility.\n",
    "\n",
    "First, a note about utility. From a static retail presentation perspective \n",
    "(buy X together with Y), the shopper's attention can probably only handle a \n",
    "couple of rules. Coupon and web offer generating systems have no such limit, \n",
    "because, while one or two offers are presented to a give customer at a given \n",
    "time, other customers, and this customer at a different time may receive \n",
    "different offers.\n",
    "\n",
    "Many rules come in pairs that are mirror images of one another, \n",
    "so we can tackle them that way.\n",
    "\n",
    "The first rule is certain so no need to make an offer.\n",
    "\n",
    "All remaining rules involve mascara, mostly as a consequent. Mascara is a good \n",
    "bet as a companion product in general -- say for a retail display. \n",
    "\n",
    "Rules 2-10 could be consolidated into a general offer covering the 5 products \n",
    "that keep reappearing in these \"multi-item\" rules: eyeliner, mascara, concealer,\n",
    "eyeshadow, and blush. These seem to be the favorites of big spenders, so a \n",
    "\"buy 3, 50% off on two others\" or something similar might work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 14.5: Course ratings\n",
    "The Institute for Statistics Education at Statistics.com asks students to rate a variety of aspects of a course as soon as the student completes it. The Institute is contemplating instituting a recommendation system that would provide students with recommendations for additional courses as soon as they submit their rating for a completed course.  Consider the excerpt from student ratings of online statistics courses shown in Table 14.7, and the problem of what to recommend to student E.N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SQL</th>\n",
       "      <th>Spatial</th>\n",
       "      <th>PA1</th>\n",
       "      <th>DM in R</th>\n",
       "      <th>Python</th>\n",
       "      <th>Forecast</th>\n",
       "      <th>R Prog</th>\n",
       "      <th>Hadoop</th>\n",
       "      <th>Regression</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LN</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MH</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JH</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EN</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DU</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FL</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GL</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AH</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RW</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MG</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AF</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KG</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DS</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            SQL  Spatial  PA1  DM in R  Python  Forecast  R Prog  Hadoop  \\\n",
       "Unnamed: 0                                                                 \n",
       "LN          4.0      NaN  NaN      NaN     3.0       2.0     4.0     NaN   \n",
       "MH          3.0      4.0  NaN      NaN     4.0       NaN     NaN     NaN   \n",
       "JH          2.0      2.0  NaN      NaN     NaN       NaN     NaN     NaN   \n",
       "EN          4.0      NaN  NaN      4.0     NaN       NaN     4.0     NaN   \n",
       "DU          4.0      4.0  NaN      NaN     NaN       NaN     NaN     NaN   \n",
       "FL          NaN      4.0  NaN      NaN     NaN       NaN     NaN     NaN   \n",
       "GL          NaN      4.0  NaN      NaN     NaN       NaN     NaN     NaN   \n",
       "AH          NaN      3.0  NaN      NaN     NaN       NaN     NaN     NaN   \n",
       "SA          NaN      NaN  4.0      NaN     NaN       NaN     NaN     NaN   \n",
       "RW          NaN      NaN  2.0      NaN     NaN       NaN     NaN     4.0   \n",
       "BA          NaN      NaN  4.0      NaN     NaN       NaN     NaN     NaN   \n",
       "MG          NaN      NaN  4.0      NaN     NaN       4.0     NaN     NaN   \n",
       "AF          NaN      NaN  4.0      NaN     NaN       NaN     NaN     NaN   \n",
       "KG          NaN      NaN  3.0      NaN     NaN       NaN     NaN     NaN   \n",
       "DS          4.0      NaN  NaN      2.0     NaN       NaN     4.0     NaN   \n",
       "\n",
       "            Regression  \n",
       "Unnamed: 0              \n",
       "LN                 2.0  \n",
       "MH                 NaN  \n",
       "JH                 NaN  \n",
       "EN                 3.0  \n",
       "DU                 NaN  \n",
       "FL                 NaN  \n",
       "GL                 NaN  \n",
       "AH                 NaN  \n",
       "SA                 NaN  \n",
       "RW                 NaN  \n",
       "BA                 NaN  \n",
       "MG                 NaN  \n",
       "AF                 NaN  \n",
       "KG                 NaN  \n",
       "DS                 NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df = pd.read_csv(DATA / 'courserating.csv')\n",
    "rating_df = rating_df.set_index('Unnamed: 0')\n",
    "rating_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 14.5.a\n",
    "First consider a user-based collaborative filter.  This requires computing correlations between all student pairs. \n",
    "For which students is it possible to compute correlations with E.N.? Compute them.\n",
    "\n",
    "We need to identify the users that share ratings with E.N. These are: L.N., M.H., J.H., D.U., and D.S. However, only L.N. and D.S. share more than one rating with E.N. \n",
    "\n",
    "To compute this correlation, we first compute average rating by each of these \n",
    "students.  Note that the average is computed over a different number of \n",
    "courses for each of these students, because they each rated a different set \n",
    "of courses.\n",
    "\n",
    "Average ratings:\n",
    "\n",
    "- LN: (4 + 3 + 2 + 4 + 2) / 5 = 3\n",
    "- EN: (4 + 4 + 4 + 3) / 4 = 3.75\n",
    "- DS: (4 + 2 + 4) / 3 = 3.33\n",
    "\n",
    "Co-rated courses for users EN and LN: SQL, R Prog, Regression.\n",
    "\n",
    "- Denominator LN: sqrt((4-3)^2 + (4-3)^2 + (2-3)^2) = 1.732051\n",
    "- Denominator EN: sqrt((4-3.75)^2 + (4-3.75)^2 + (3-3.75)^2) = 0.8291562\n",
    "\n",
    "**Corr(LN, EN) = ((4-3)*(4-3.75) + (4-3)*(4-3.75) + (2-3)*(3-3.75)) / (1.732051 * 0.8291562) = 0.8703882**\n",
    "\n",
    "Co-rated courses for users EN and LN: SQL, DM in R, R Prog.\n",
    "\n",
    "- Denominator EN: sqrt((4-3.75)^2 + (4-3.75)^2 + (4-3.75)^2) = 0.4330127\n",
    "- Denominator DS: sqrt((4-3.33)^2 + (2-3.33)^2 + (4-3.33)^2) = 1.633003\n",
    "\n",
    "**Corr(EN, DS) = ((4-3.75)*(4-3.33) + (4-3.75)*(2-3.33) + (4-3.75)*(4-3.33)) / (0.4330127 * 1.633003) = 0.003535513**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 14.5.b\n",
    "Based on the single nearest student to E.N., which single course should we recommend to E.N.? Explain why. \n",
    "\n",
    "From the correlations computed in (a) above, student LN is nearest to EN. Among the courses that LN has taken (but not taken by EN), Python is highly preferred by LN. So Python should be recommended to EN.\n",
    "\n",
    "\n",
    "## Solution 14.5.c\n",
    "Use _scikit-learn_ function `sklearn.metrics.pairwise.cosine_similarity` to compute the cosine similarity between users. \n",
    "\n",
    "Co-rated courses for users EN and LN: SQL, R Prog, Regression.\n",
    "\n",
    "- Denominator LN: sqrt(4^2 + 4^2 + 2^2) = 6\n",
    "- Denominator EN: sqrt(4^2 + 4^2 + 3^2) = 6.403124\n",
    "\n",
    "**Cosine(LN, EN) = (4*4 + 4*4 + 2*3) / (6 * 6.403124) = 0.9891005**\n",
    "\n",
    "Co-rated courses for users EN and LN: SQL, DM in R, R Prog.\n",
    "\n",
    "- Denominator EN: sqrt(4^2 + 4^2 + 4^2) = 6.928203\n",
    "- Denominator DS: sqrt(4^2 + 2^2 + 4^2) = 6\n",
    "\n",
    "**Cosine(EN, DS) = (4*4 + 4*2 + 4*4) / (6.928203 * 6) = 0.9622505**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine(LN, EN) = "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.9891004919611718\n",
      "cosine(EN, DS) =  0.9622504486493764\n"
     ]
    }
   ],
   "source": [
    "print('cosine(LN, EN) = ',cosine_similarity(rating_df.loc[['LN', 'EN'], ['SQL', 'R Prog', 'Regression']])[0, 1])\n",
    "print('cosine(EN, DS) = ',cosine_similarity(rating_df.loc[['EN', 'DS'], ['SQL', 'DM in R', 'R Prog']])[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an implementation of cosine similarity that handles NaN data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>LN</th>\n",
       "      <th>MH</th>\n",
       "      <th>JH</th>\n",
       "      <th>EN</th>\n",
       "      <th>DU</th>\n",
       "      <th>FL</th>\n",
       "      <th>GL</th>\n",
       "      <th>AH</th>\n",
       "      <th>SA</th>\n",
       "      <th>RW</th>\n",
       "      <th>BA</th>\n",
       "      <th>MG</th>\n",
       "      <th>AF</th>\n",
       "      <th>KG</th>\n",
       "      <th>DS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LN</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.98910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MH</th>\n",
       "      <td>0.9600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989949</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.989949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JH</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.989949</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EN</th>\n",
       "      <td>0.9891</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.96225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DU</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.989949</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FL</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GL</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AH</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RW</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MG</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AF</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KG</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DS</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.96225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Unnamed: 0      LN        MH        JH       EN        DU   FL   GL   AH   SA  \\\n",
       "Unnamed: 0                                                                      \n",
       "LN          1.0000  0.960000  1.000000  0.98910  1.000000  NaN  NaN  NaN  NaN   \n",
       "MH          0.9600  1.000000  0.989949  1.00000  0.989949  1.0  1.0  1.0  NaN   \n",
       "JH          1.0000  0.989949  1.000000  1.00000  1.000000  1.0  1.0  1.0  NaN   \n",
       "EN          0.9891  1.000000  1.000000  1.00000  1.000000  NaN  NaN  NaN  NaN   \n",
       "DU          1.0000  0.989949  1.000000  1.00000  1.000000  1.0  1.0  1.0  NaN   \n",
       "FL             NaN  1.000000  1.000000      NaN  1.000000  1.0  1.0  1.0  NaN   \n",
       "GL             NaN  1.000000  1.000000      NaN  1.000000  1.0  1.0  1.0  NaN   \n",
       "AH             NaN  1.000000  1.000000      NaN  1.000000  1.0  1.0  1.0  NaN   \n",
       "SA             NaN       NaN       NaN      NaN       NaN  NaN  NaN  NaN  1.0   \n",
       "RW             NaN       NaN       NaN      NaN       NaN  NaN  NaN  NaN  1.0   \n",
       "BA             NaN       NaN       NaN      NaN       NaN  NaN  NaN  NaN  1.0   \n",
       "MG          1.0000       NaN       NaN      NaN       NaN  NaN  NaN  NaN  1.0   \n",
       "AF             NaN       NaN       NaN      NaN       NaN  NaN  NaN  NaN  1.0   \n",
       "KG             NaN       NaN       NaN      NaN       NaN  NaN  NaN  NaN  1.0   \n",
       "DS          1.0000  1.000000  1.000000  0.96225  1.000000  NaN  NaN  NaN  NaN   \n",
       "\n",
       "Unnamed: 0   RW   BA   MG   AF   KG       DS  \n",
       "Unnamed: 0                                    \n",
       "LN          NaN  NaN  1.0  NaN  NaN  1.00000  \n",
       "MH          NaN  NaN  NaN  NaN  NaN  1.00000  \n",
       "JH          NaN  NaN  NaN  NaN  NaN  1.00000  \n",
       "EN          NaN  NaN  NaN  NaN  NaN  0.96225  \n",
       "DU          NaN  NaN  NaN  NaN  NaN  1.00000  \n",
       "FL          NaN  NaN  NaN  NaN  NaN      NaN  \n",
       "GL          NaN  NaN  NaN  NaN  NaN      NaN  \n",
       "AH          NaN  NaN  NaN  NaN  NaN      NaN  \n",
       "SA          1.0  1.0  1.0  1.0  1.0      NaN  \n",
       "RW          1.0  1.0  1.0  1.0  1.0      NaN  \n",
       "BA          1.0  1.0  1.0  1.0  1.0      NaN  \n",
       "MG          1.0  1.0  1.0  1.0  1.0      NaN  \n",
       "AF          1.0  1.0  1.0  1.0  1.0      NaN  \n",
       "KG          1.0  1.0  1.0  1.0  1.0      NaN  \n",
       "DS          NaN  NaN  NaN  NaN  NaN  1.00000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cosine_similarity_NA(data):\n",
    "    m = data.shape[0]\n",
    "    # Initialize the similarity matrix to np.nan\n",
    "    result = np.full((m, m), np.nan)\n",
    "    # Iterate over all pairs of columns\n",
    "    for i in range(m):\n",
    "        # maski is true if a value exists in column i\n",
    "        maski = ~np.isnan(data.iloc[i])\n",
    "        for j in range(i, m):\n",
    "            # maskij is true if a value exists in both column i and j\n",
    "            maskij = maski & ~np.isnan(data.iloc[j])\n",
    "            if np.any(maskij):\n",
    "                # if there are values in both columns, calculate the cosine similarity\n",
    "                # for these\n",
    "                result[i, j] = 1 - cosine(data.iloc[i][maskij], data.iloc[j][maskij])\n",
    "                result[j, i] = result[i, j]\n",
    "    return pd.DataFrame(result, columns=data.index, index=data.index)\n",
    "\n",
    "cosineSimilarity = cosine_similarity_NA(rating_df)\n",
    "cosineSimilarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate the cosine similarity after converting the rating matrix into binary form (course taken or not). In this case, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine(LN, EN) =  0.6708203932499369\n",
      "cosine(EN, DS) =  0.8660254037844388\n"
     ]
    }
   ],
   "source": [
    "binary_df = rating_df.copy()\n",
    "binary_df[~np.isnan(binary_df)] = 1\n",
    "binary_df[np.isnan(binary_df)] = 0\n",
    "print('cosine(LN, EN) = ', cosine_similarity(binary_df)[0, 3])\n",
    "print('cosine(EN, DS) = ', cosine_similarity(binary_df)[3, 14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 14.5.d\n",
    "Based on the cosine similarities of the nearest students to E.N., which course should be recommended to E.N.?\n",
    "\n",
    "From the cosine similarities based on course ratings, student LN is nearest to EN. Among the courses \n",
    "that LN has taken (but not taken by EN), Python is highly preferred by LN. \n",
    "So Python should be recommended to EN.\n",
    "\n",
    "If we use the binary matrix, student DS is more similar to EN based on courses taken. However, as DS hasn't taken any courses other than the ones EN already took, we cannot make a recommendation in this case.\n",
    "\n",
    "## Solution 14.5.e\n",
    "What is the conceptual difference between using the\n",
    "correlation \n",
    "as opposed to cosine similarities?\n",
    "\\[_Hint_: how are the missing values in the matrix handled in each case?\\]\n",
    "\n",
    "If we consider the rating matrix, both methods basically only consider co-rated items. Correlation uses the not co-rated items to calculate the averages which will impact the correlation. \n",
    "\n",
    "If we calculate the cosine-similarity after converting to a binary form, we use all items in the similarity calculation. Using the actual ratings only on co-rated items does not take into \n",
    "consideration items that are not co-rated, which may be useful information. \n",
    "\n",
    "Using the binary form, is more useful if not all items are rated by most users. On the other hand, if most items are rated by most users, using the actual ratings will add power to the analysis, compared to just using binary data.\n",
    "\n",
    "\n",
    "\n",
    "## Solution 14.5.f\n",
    "With large datasets, it is computationally difficult to compute user-based recommendations in real time, and an item-based approach is used instead. Returning to the rating data (not the binary matrix), let's now take that approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 14.5.f.i\n",
    "If the goal is still to find a recommendation for E.N., for which course pairs is it possible and useful to calculate correlations?  \n",
    "\n",
    "\n",
    "There is enough data to find correlations for the following pairs:    \n",
    "- SQL - Spatial    \n",
    "- SQL - DM in R    \n",
    "- SQL - Python    \n",
    "- DM in R - R Prog    \n",
    "- Spatial - Python\n",
    "\n",
    "However, EN has already taken SQL, DM in R, and R Prog.  Hence, only the Spatial and Python correlations are useful.\n",
    "\n",
    "### Solution 14.5.f.ii\n",
    "Just looking at the data, and without yet calculating course pair correlations, which course would you recommend to E.N., relying on item-based filtering?  Calculate two course pair correlations involving your guess and report the results. \n",
    "\n",
    "The SQL - Spatial ratings match the best, and there are more co-rated items, \n",
    "so Spatial would be the best guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.99037514]\n",
      " [0.99037514 1.        ]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SQL</th>\n",
       "      <th>Spatial</th>\n",
       "      <th>PA1</th>\n",
       "      <th>DM in R</th>\n",
       "      <th>Python</th>\n",
       "      <th>Forecast</th>\n",
       "      <th>R Prog</th>\n",
       "      <th>Hadoop</th>\n",
       "      <th>Regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SQL</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.948683</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.980581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spatial</th>\n",
       "      <td>0.990375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DM in R</th>\n",
       "      <td>0.948683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.948683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Python</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forecast</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R Prog</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.948683</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.980581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hadoop</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regression</th>\n",
       "      <td>0.980581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SQL   Spatial  PA1   DM in R  Python  Forecast    R Prog  \\\n",
       "SQL         1.000000  0.990375  NaN  0.948683    0.96       1.0  1.000000   \n",
       "Spatial     0.990375  1.000000  NaN       NaN    1.00       NaN       NaN   \n",
       "PA1              NaN       NaN  1.0       NaN     NaN       1.0       NaN   \n",
       "DM in R     0.948683       NaN  NaN  1.000000     NaN       NaN  0.948683   \n",
       "Python      0.960000  1.000000  NaN       NaN    1.00       1.0  1.000000   \n",
       "Forecast    1.000000       NaN  1.0       NaN    1.00       1.0  1.000000   \n",
       "R Prog      1.000000       NaN  NaN  0.948683    1.00       1.0  1.000000   \n",
       "Hadoop           NaN       NaN  1.0       NaN     NaN       NaN       NaN   \n",
       "Regression  0.980581       NaN  NaN  1.000000    1.00       1.0  0.980581   \n",
       "\n",
       "            Hadoop  Regression  \n",
       "SQL            NaN    0.980581  \n",
       "Spatial        NaN         NaN  \n",
       "PA1            1.0         NaN  \n",
       "DM in R        NaN    1.000000  \n",
       "Python         NaN    1.000000  \n",
       "Forecast       NaN    1.000000  \n",
       "R Prog         NaN    0.980581  \n",
       "Hadoop         1.0         NaN  \n",
       "Regression     NaN    1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cosine_similarity(rating_df.loc[['MH', 'JH', 'DU'], ['SQL', 'Spatial']].transpose()))\n",
    "cosine_similarity_NA(rating_df.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 14.5.g\n",
    "Apply item-based collaborative filtering to this dataset (using Python) and based on the results, recommend a course to E.N. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "SQL 3.7504416393899813\n",
      "Spatial 4\n",
      "PA1 3.433333333333333\n",
      "DM in R 3.743416490252569\n",
      "Python 3.6621621621621623\n",
      "Forecast 3.6666666666666665\n",
      "R Prog 3.7504416393899813\n",
      "Hadoop 3.433333333333333\n",
      "Regression 3.747548783981962\n"
     ]
    }
   ],
   "source": [
    "# convert the rating_df dataframe into a format suitable for the Surprise package\n",
    "ratings = []\n",
    "for customer, row in rating_df.iterrows():\n",
    "    for course, value in row.iteritems():\n",
    "        if np.isnan(value): continue\n",
    "        ratings.append([customer, course, value])\n",
    "ratings = pd.DataFrame(ratings, columns=['customer', 'course', 'rating'])\n",
    "\n",
    "reader = Reader(rating_scale=(1, 4))\n",
    "data = Dataset.load_from_df(ratings, reader)\n",
    "trainset = data.build_full_trainset()\n",
    "# compute cosine similarities between items\n",
    "sim_options = {'name': 'cosine', 'user_based': False}  \n",
    "algo = KNNBasic(sim_options=sim_options)\n",
    "algo.fit(trainset)\n",
    "\n",
    "courses = rating_df.columns\n",
    "for course in courses: \n",
    "    print(course, algo.predict('EN', course).est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The item-based collaborative filtering recommends the **Spatial** course to E.N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
