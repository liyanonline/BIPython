{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7: k-Nearest Neighbors (k-NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> (c) 2019-2020 Galit Shmueli, Peter C. Bruce, Peter Gedeck \n",
    ">\n",
    "> _Data Mining for Business Analytics: Concepts, Techniques, and Applications in Python_ (First Edition) \n",
    "> Galit Shmueli, Peter C. Bruce, Peter Gedeck, and Nitin R. Patel. 2019.\n",
    ">\n",
    "> Date: 2020-03-08\n",
    ">\n",
    "> Python Version: 3.8.2\n",
    "> Jupyter Notebook Version: 5.6.1\n",
    ">\n",
    "> Packages:\n",
    ">   - pandas: 1.0.1\n",
    ">   - scikit-learn: 0.22.2\n",
    ">\n",
    "> The assistance from Mr. Kuber Deokar and Ms. Anuja Kulkarni in preparing these solutions is gratefully acknowledged.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages for this chapter\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import pairwise\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor #, NearestNeighbors\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working directory:\n",
    "#\n",
    "# We assume that data are kept in the same directory as the notebook. If you keep your \n",
    "# data in a different folder, replace the argument of the `Path`\n",
    "DATA = Path('.')\n",
    "# and then load data using \n",
    "#\n",
    "# pd.read_csv(DATA / ‘filename.csv’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7.1 Calculating Distance with Categorical Predictors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise with a tiny dataset illustrates the calculation of Euclidean distance, and the creation of binary dummies. The online education company Statistics.com segments its customers and prospects into three main categories: IT professionals (IT), statisticians (Stat), and other (Other). It also tracks, for each customer, the number of years since first contact (years). Consider the following customers; information about whether they have taken a course or not (the outcome to be predicted) is included:\n",
    "\n",
    "Customer 1: Stat, 1 year, did not take course\n",
    "\n",
    "Customer 2: Other, 1.1 year, took course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7.1.a__ Consider now the following new prospect:\n",
    "\n",
    "Prospect 1: IT, 1 year\n",
    "\n",
    "Using the above information on the two customers and one prospect, create one dataset for all three with the categorical predictor variable transformed into 2 binaries, and a similar dataset with the categorical predictor variable transformed into 3\n",
    "binaries.\n",
    "\n",
    "__7.1.b.__ For each derived dataset, calculate the Euclidean distance between the prospect and each of the other two customers. (Note: while it is typical to normalize data for k-NN, this is not an iron-clad rule and you may proceed here without normalization.)\n",
    "\n",
    "__7.1.c.__ Using k-NN with k = 1, classify the prospect as taking or not taking a course using each of the two derived datasets. Does it make a difference whether you use 2 or 3 dummies?\n",
    "\n",
    "__Answer:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Name  Stat  Other  IT  Years  CourseTaken\n",
      "0  Customer1     1      0   0    1.0          0.0\n",
      "1  Customer2     0      1   0    1.1          1.0\n",
      "2  Customer3     0      0   1    1.0          NaN\n"
     ]
    }
   ],
   "source": [
    "# create a data frame, containing the following columns\n",
    "# column 'Name\" containing customer names, i.e. Customer1, Customer2 and Cistomer3.\n",
    "# columns 'Stat', 'Other' and 'IT' as three dummies for three main categories of customers. \n",
    "# column 'TookCourse' containing whether that customer took the course or not, where 1 indicates a course taken and 0 otherwise.\n",
    "data = [['Customer1', 1, 0, 0, 1, 0], ['Customer2', 0, 1, 0, 1.1, 1], ['Customer3', 0, 0, 1, 1]]\n",
    "df = pd.DataFrame(data,columns=['Name','Stat','Other', 'IT', 'Years', 'CourseTaken'])\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Customer3 is the new prospect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Name</th>\n",
       "      <th>Customer1</th>\n",
       "      <th>Customer2</th>\n",
       "      <th>Customer3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Customer1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.004988</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer2</th>\n",
       "      <td>1.004988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.004988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer3</th>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.004988</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Name       Customer1  Customer2  Customer3\n",
       "Name                                      \n",
       "Customer1   0.000000   1.004988   1.414214\n",
       "Customer2   1.004988   0.000000   1.004988\n",
       "Customer3   1.414214   1.004988   0.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate euclidean distances between customers 1 and 3 and customers 2 and 3 using two dummies.\n",
    "# drop the dummy 'Other'\n",
    "col = ['Stat', 'IT', 'Years']\n",
    "df2dummies = df[col]\n",
    "d = pairwise.pairwise_distances(df2dummies, metric='euclidean')\n",
    "# prettify distance matrix by converting to a dataframe\n",
    "pd.DataFrame(d, columns=df.Name, index=df.Name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use two dummies, the prospect (Customer3) is closest to Customer 2. in this case Euclidean distance between the prospect and the second customer is less than the euclidean distance between the prospect and the first customer. Therefore we classify the new customer as taking the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Name</th>\n",
       "      <th>Customer1</th>\n",
       "      <th>Customer2</th>\n",
       "      <th>Customer3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Customer1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.417745</td>\n",
       "      <td>1.414214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer2</th>\n",
       "      <td>1.417745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.417745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customer3</th>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.417745</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Name       Customer1  Customer2  Customer3\n",
       "Name                                      \n",
       "Customer1   0.000000   1.417745   1.414214\n",
       "Customer2   1.417745   0.000000   1.417745\n",
       "Customer3   1.414214   1.417745   0.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate euclidean distances between customers 1 and 3 and customers 2 and 3 using all three dummies.\n",
    "from sklearn.metrics import pairwise\n",
    "# use only relevant columns\n",
    "col = ['Stat', 'Other', 'IT', 'Years']\n",
    "df3dummies = df[col]\n",
    "d = pairwise.pairwise_distances(df3dummies, metric='euclidean')\n",
    "# prettify distance matrix by converting to a dataframe\n",
    "pd.DataFrame(d, columns=df.Name, index=df.Name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use all three dummies, the prospect (Customer3) is closest to Customer1. In this case the euclidean distance between the prospect and the first customer is less than the euclidean distance between the prospect and the second customer. Therefore we classify the new customer as \"not taking the course\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7.2 Personal Loan Acceptance\n",
    "\n",
    "Universal Bank is a relatively young bank growing rapidly in terms of overall customer acquisition. The majority of these customers are liability customers (depositors) with varying sizes of relationship with the bank. The customer base of asset customers (borrowers) is quite small, and the bank is interested in expanding this base rapidly to bring in more loan business. In particular, it wants to explore ways of converting its liability customers to personal loan customers (while retaining them as depositors).\n",
    "\n",
    "A campaign that the bank ran last year for liability customers showed a healthy conversion rate of over 9% success. This has encouraged the retail marketing department to devise smarter campaigns with better target marketing. The goal is to use\n",
    "k-NN to predict whether a new customer will accept a loan offer. This will serve as the basis for the design of a new campaign.\n",
    "\n",
    "The file _UniversalBank.csv_ contains data on 5000 customers. The data include customer demographic information (age, income, etc.), the customer’s relationship with the bank (mortgage, securities account, etc.), and the customer response to the last personal loan campaign (Personal Loan). Among these 5000 customers, only 480 (= 9.6%) accepted the personal loan that was offered to them in the earlier campaign.\n",
    "\n",
    "Partition the data into training (60%) and validation (40%) sets.\n",
    "\n",
    "__7.2.a__ Consider the following customer:\n",
    "\n",
    "Age = 40, Experience = 10, Income = 84, Family = 2, CCAvg = 2, Education_1= 0, Education_2 = 1, Education_3 = 0, Mortgage = 0, Securities Account = 0, CD Account = 0, Online = 1, and Credit Card = 1. Perform a k-NN classification with all predictors except ID and ZIP code using k = 1. Remember to transform categorical predictors with more than two categories into dummy variables first. Specify the success class as 1 (loan acceptance), and use the default cutoff value of 0.5. How would this customer be classified?\n",
    "\n",
    "__Answer:__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation\n",
    "Load the data and remove unnecessary columns (ID, ZIP Code). Split the data into training (60%) and validation (40%) sets (use `random_state=1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Experience  Income  Family  CCAvg  Education  Mortgage  Personal Loan  \\\n",
       "0   25           1      49       4    1.6          1         0              0   \n",
       "1   45          19      34       3    1.5          1         0              0   \n",
       "2   39          15      11       1    1.0          1         0              0   \n",
       "3   35           9     100       1    2.7          2         0              0   \n",
       "4   35           8      45       4    1.0          2         0              0   \n",
       "\n",
       "   Securities Account  CD Account  Online  CreditCard  \n",
       "0                   1           0       0           0  \n",
       "1                   1           0       0           0  \n",
       "2                   0           0       0           0  \n",
       "3                   0           0       0           0  \n",
       "4                   0           0       0           1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "bank_df = pd.read_csv(DATA / 'UniversalBank.csv')\n",
    "\n",
    "# Drop ID and zip code columns\n",
    "bank_df = bank_df.drop(columns=['ID', 'ZIP Code'])\n",
    "\n",
    "# Make sure that the result is as expected\n",
    "bank_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age',\n",
       " 'Experience',\n",
       " 'Income',\n",
       " 'Family',\n",
       " 'CCAvg',\n",
       " 'Education',\n",
       " 'Mortgage',\n",
       " 'Personal_Loan',\n",
       " 'Securities_Account',\n",
       " 'CD_Account',\n",
       " 'Online',\n",
       " 'CreditCard']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modify column names\n",
    "bank_df.columns = [c.replace(' ', '_').replace('=', '_') for c in bank_df.columns]\n",
    "list(bank_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal_Loan</th>\n",
       "      <th>Securities_Account</th>\n",
       "      <th>CD_Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "      <th>Education_1</th>\n",
       "      <th>Education_2</th>\n",
       "      <th>Education_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Experience  Income  Family  CCAvg  Mortgage  Personal_Loan  \\\n",
       "0   25           1      49       4    1.6         0              0   \n",
       "1   45          19      34       3    1.5         0              0   \n",
       "2   39          15      11       1    1.0         0              0   \n",
       "3   35           9     100       1    2.7         0              0   \n",
       "4   35           8      45       4    1.0         0              0   \n",
       "\n",
       "   Securities_Account  CD_Account  Online  CreditCard  Education_1  \\\n",
       "0                   1           0       0           0            1   \n",
       "1                   1           0       0           0            1   \n",
       "2                   0           0       0           0            1   \n",
       "3                   0           0       0           0            0   \n",
       "4                   0           0       0           1            0   \n",
       "\n",
       "   Education_2  Education_3  \n",
       "0            0            0  \n",
       "1            0            0  \n",
       "2            0            0  \n",
       "3            1            0  \n",
       "4            1            0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dummy variables for categorical variable, we consider Education as categorical variable\n",
    "bank_df['Education'] = bank_df['Education'].astype('category')\n",
    "bank_df = pd.get_dummies(bank_df, prefix_sep='_', drop_first=False)\n",
    "bank_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (3000, 14) Validation set: (2000, 14)\n"
     ]
    }
   ],
   "source": [
    "# split dataset into training (60%) and validation (40%) sets\n",
    "train_df, valid_df = train_test_split(bank_df, test_size=0.4, random_state=1)\n",
    "print('Training set:', train_df.shape, 'Validation set:', valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Securities_Account</th>\n",
       "      <th>CD_Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "      <th>Education_1</th>\n",
       "      <th>Education_2</th>\n",
       "      <th>Education_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>84</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Experience  Income  Family  CCAvg  Mortgage  Securities_Account  \\\n",
       "0   40          10      84       2      2         0                   0   \n",
       "\n",
       "   CD_Account  Online  CreditCard  Education_1  Education_2  Education_3  \n",
       "0           0       1           1            0            1            0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new customer\n",
    "newCustomer = pd.DataFrame([{'Age': 40, 'Experience': 10, 'Income': 84, 'Family': 2, 'CCAvg': 2, 'Mortgage': 0,\n",
    "                             'Securities_Account': 0, 'CD_Account': 0, 'Online': 1, 'CreditCard': 1, 'Education_1': 0, \n",
    "                             'Education_2': 1, 'Education_3': 0}],\n",
    "                            columns=['Age', 'Experience', 'Income', 'Family', 'CCAvg', 'Mortgage', 'Securities_Account',\n",
    "                                   'CD_Account', 'Online', 'CreditCard', 'Education_1', 'Education_2', 'Education_3'])\n",
    "newCustomer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Age  Experience    Income    Family     CCAvg  Mortgage  \\\n",
      "0 -0.486446   -0.901063  0.220892 -0.352127  0.035689 -0.559242   \n",
      "\n",
      "   Securities_Account  CD_Account   Online  CreditCard  Education_1  \\\n",
      "0           -0.337025   -0.252646  0.83419     1.53728    -0.838795   \n",
      "\n",
      "   Education_2  Education_3  \n",
      "0     1.591719    -0.660895  \n"
     ]
    }
   ],
   "source": [
    "# normalize training and validation sets. The transformation is trained using the training set only.\n",
    "# if you don't convert the integer columns to real numbers (float64), \n",
    "# the StandardScaler will raise a DataConversionWarning. This is expected\n",
    "outcome = 'Personal_Loan'\n",
    "predictors = list(bank_df.columns)\n",
    "predictors.remove(outcome)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(train_df[predictors])\n",
    "scaler.transform(train_df[predictors])\n",
    "# Transform the predictors of training, validation and newCustomer\n",
    "train_X = scaler.transform(train_df[predictors])\n",
    "train_y = train_df[outcome]\n",
    "valid_X = scaler.transform(valid_df[predictors])\n",
    "valid_y = valid_df[outcome]\n",
    "newCustomerNorm = pd.DataFrame(scaler.transform(newCustomer), \n",
    "                               columns=['Age', 'Experience', 'Income', 'Family', 'CCAvg', 'Mortgage', 'Securities_Account',\n",
    "                                   'CD_Account', 'Online', 'CreditCard', 'Education_1', 'Education_2', 'Education_3'])\n",
    "print(newCustomerNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k-NN using k = 1\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicted class\n",
    "knn.predict(newCustomerNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicted probability\n",
    "knn.predict_proba(newCustomerNorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New customer is predicted to not accept a loan offer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7.2.b__ What is a choice of k that balances between overfitting and ignoring the predictor information?\n",
    "\n",
    "__Answer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.9535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.9565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.9520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.9475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>0.9465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13</td>\n",
       "      <td>0.9450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>0.9440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>0.9415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>0.9405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k  accuracy\n",
       "0   1    0.9545\n",
       "1   3    0.9535\n",
       "2   5    0.9565\n",
       "3   7    0.9520\n",
       "4   9    0.9475\n",
       "5  11    0.9465\n",
       "6  13    0.9450\n",
       "7  15    0.9440\n",
       "8  17    0.9415\n",
       "9  19    0.9405"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a classifier for different values of k\n",
    "results = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k).fit(train_X, train_y)\n",
    "    results.append({\n",
    "        'k': k,\n",
    "        'accuracy': accuracy_score(valid_y, knn.predict(valid_X))\n",
    "    })\n",
    "\n",
    "# Convert results to a pandas data frame\n",
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy vs. k\n",
    "_ = results.plot.scatter(x='k', y='accuracy', xlim=[0, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the best k, which minimizes the misclassification rate in the validation set. Our best k is `k=5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7.2.c.__ Show the confusion matrix for the validation data that results from using the best k.\n",
    "\n",
    "__Answer__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1803    4]\n",
      " [  83  110]]\n",
      "Accuracy : 0.9565\n"
     ]
    }
   ],
   "source": [
    "# k-NN model for k = 5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(train_X, train_y)\n",
    "\n",
    "knnPredOpt = knn.predict(valid_X)\n",
    "print(confusion_matrix(valid_y, knnPredOpt))\n",
    "print('Accuracy :', accuracy_score(valid_y, knnPredOpt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7.2.d.__ Consider the following customer: Age = 40, Experience = 10, Income = 84, Family = 2, CCAvg = 2, Education_1 = 0, Education_2 = 1, Education_3 = 0, Mortgage = 0, Securities Account = 0, CD Account = 0, Online = 1 and Credit Card = 1. Classify the customer using the best k.\n",
    "\n",
    "__Answer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicted class\n",
    "knn.predict(newCustomerNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicted probability\n",
    "knn.predict_proba(newCustomerNorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New customer is predicted to not accept a loan offer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7.2.e.__ Repartition the data, this time into training, validation, and test sets (50% : 30% : 20%). Apply the k-NN method with the k chosen above. Compare the confusion matrix of the test set with that of the training and validation sets. Comment on the differences and their reason.\n",
    "\n",
    "__Answer__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training :  (2500, 14)\n",
      "Validation :  (1500, 14)\n",
      "Test :  (1000, 14)\n"
     ]
    }
   ],
   "source": [
    "# partition the data into training (50%), validation (30%) and test (20%) sets\n",
    "train_df, temp_df = train_test_split(bank_df, test_size=0.5, random_state=1)\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.4, random_state=1)\n",
    "\n",
    "print('Training : ', train_df.shape)\n",
    "print('Validation : ', valid_df.shape)\n",
    "print('Test : ', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize training and validation sets. The transformation is trained using the training set only.\n",
    "# if you don't convert the integer columns to real numbers (float64), \n",
    "# the StandardScaler will raise a DataConversionWarning. This is expected\n",
    "outcome = 'Personal_Loan'\n",
    "predictors = list(bank_df.columns)\n",
    "predictors.remove(outcome)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(train_df[predictors])\n",
    "\n",
    "# Transform the predictors of training validation and newCustomer\n",
    "train_X = scaler.transform(train_df[predictors])\n",
    "train_y = train_df[outcome]\n",
    "valid_X = scaler.transform(valid_df[predictors])\n",
    "valid_y = valid_df[outcome]\n",
    "test_X = scaler.transform(test_df[predictors])\n",
    "test_y = test_df[outcome]\n",
    "test_X = pd.DataFrame(test_X, columns=['Age', 'Experience', 'Income', 'Family', 'CCAvg', 'Mortgage', 'Securities_Account',\n",
    "                                   'CD_Account', 'Online', 'CreditCard', 'Education_1', 'Education_2', 'Education_3'])\n",
    "test_y = pd.DataFrame(test_y, columns=['Personal_Loan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k-NN model for best k = 5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2255    4]\n",
      " [  75  166]]\n",
      "Accuracy : 0.9684\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix of training set\n",
    "knnPredOpt = knn.predict(train_X)\n",
    "print(confusion_matrix(train_y, knnPredOpt))\n",
    "print('Accuracy :', accuracy_score(train_y, knnPredOpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1346    3]\n",
      " [  67   84]]\n",
      "Accuracy : 0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix of validation set\n",
    "knnPredOpt = knn.predict(valid_X)\n",
    "print(confusion_matrix(valid_y, knnPredOpt))\n",
    "print('Accuracy :', accuracy_score(valid_y, knnPredOpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[907   5]\n",
      " [ 35  53]]\n",
      "Accuracy : 0.96\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix of test set\n",
    "knnPredOpt = knn.predict(test_X)\n",
    "print(confusion_matrix(test_y, knnPredOpt))\n",
    "print('Accuracy :', accuracy_score(test_y, knnPredOpt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error rate increases from the training set to the validation set, but decreases from the validation set to the test set.  The differences are small, but this decreased performance, at least in the test set, is unexpected but we can ignore it as difference is very small - both the training and validation sets are used in setting the optimal k so there can be overfitting.  The test set was not used to select the optimal k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7.3 Predicting Housing Median Prices\n",
    "\n",
    "The file _BostonHousing.csv_ contains information on over 500 census tracts in Boston, where for each tract multiple variables\n",
    "are recorded. The last column (CAT. MEDV) was derived from MEDV, such that it obtains the value 1 if MEDV > 30 and 0 otherwise. Consider the goal of predicting the median value (MEDV) of a tract, given the information in the first 12 columns.\n",
    "Partition the data into training (60%) and validation (40%) sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7.3.a.__ Perform a k-NN prediction with all 12 predictors (ignore the CAT. MEDV column), trying values of k from 1 to 5. Make sure to normalize the data. What is the best k? What does it mean?\n",
    "\n",
    "__Answer__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation\n",
    "Load the data and remove unnecessary columns (CAT. MEDV). Split the data into training (60%) and validation (40%) sets (use `random_state=1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "   LSTAT  MEDV  \n",
       "0   4.98  24.0  \n",
       "1   9.14  21.6  \n",
       "2   4.03  34.7  \n",
       "3   2.94  33.4  \n",
       "4   5.33  36.2  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "house_df = pd.read_csv(DATA / 'BostonHousing.csv')\n",
    "\n",
    "# Drop CAT.MEDV column\n",
    "house_df = house_df.drop(columns=['CAT. MEDV'])\n",
    "\n",
    "# Make sure that the result is as expected\n",
    "house_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (303, 13) Validation set: (203, 13)\n"
     ]
    }
   ],
   "source": [
    "# split dataset into training (60%) and validation (40%) sets\n",
    "train_df, valid_df = train_test_split(house_df, test_size=0.4, random_state=1)\n",
    "print('Training set:', train_df.shape, 'Validation set:', valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize training and validation sets. The transformation is trained using the training set only.\n",
    "# if you don't convert the integer columns to real numbers (float64), the StandardScaler will raise a DataConversionWarning. \n",
    "# This is expected\n",
    "outcome = 'MEDV'\n",
    "predictors = list(house_df.columns)\n",
    "predictors.remove(outcome)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(train_df[predictors])\n",
    "\n",
    "# Transform the predictors of training validation and newCustomer\n",
    "train_X = scaler.transform(train_df[predictors])\n",
    "train_y = train_df[outcome]\n",
    "valid_X = scaler.transform(valid_df[predictors])\n",
    "valid_y = valid_df[outcome]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.403228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.778562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.671801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.789219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.014823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k      RMSE\n",
       "0  1  5.403228\n",
       "1  2  4.778562\n",
       "2  3  4.671801\n",
       "3  4  4.789219\n",
       "4  5  5.014823"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a regressor for different values of k\n",
    "results = []\n",
    "for k in range(1, 6):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k).fit(train_X, train_y)\n",
    "    results.append({\n",
    "        'k': k,\n",
    "        'RMSE': math.sqrt(mean_squared_error(valid_y, knn.predict(valid_X)))\n",
    "    })\n",
    "\n",
    "# Convert results to a pandas data frame\n",
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here best `k = 3`. This means that, for a given record, MEDV is predicted by averaging the MEDVs for the 3 closest records, proximity being measured by the distance between the vectors of predictor values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7.3.b.__ Predict the MEDV for a tract with the following information, using the best k:\n",
    "\n",
    "CRIM = 0.2, ZN = 0, INDUS = 7, CHAS = 0, NOX = 0.538, RM = 6, AGE = 62, DIS = 4.7, RAD = 4, TAX = 307, PTRATIO = 21, LSTAT = 10.\n",
    "\n",
    "__Answer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6</td>\n",
       "      <td>62</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRIM  ZN  INDUS  CHAS    NOX  RM  AGE  DIS  RAD  TAX  PTRATIO  LSTAT\n",
       "0   0.2   0      7     0  0.538   6   62  4.7    4  307       21     10"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new tract\n",
    "newTract = pd.DataFrame([{'CRIM': 0.2, 'ZN': 0, 'INDUS': 7, 'CHAS': 0, 'NOX': 0.538, 'RM': 6, 'AGE': 62, 'DIS': 4.7, 'RAD': 4, \n",
    "                          'TAX': 307, 'PTRATIO': 21, 'LSTAT': 10}],\n",
    "                       columns=['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'LSTAT'])\n",
    "newTract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.403622</td>\n",
       "      <td>-0.481603</td>\n",
       "      <td>-0.620687</td>\n",
       "      <td>-0.293294</td>\n",
       "      <td>-0.153758</td>\n",
       "      <td>-0.358814</td>\n",
       "      <td>-0.243285</td>\n",
       "      <td>0.400608</td>\n",
       "      <td>-0.640284</td>\n",
       "      <td>-0.604731</td>\n",
       "      <td>1.197866</td>\n",
       "      <td>-0.421956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0 -0.403622 -0.481603 -0.620687 -0.293294 -0.153758 -0.358814 -0.243285   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO     LSTAT  \n",
       "0  0.400608 -0.640284 -0.604731  1.197866 -0.421956  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize new record\n",
    "newTractNorm = pd.DataFrame(scaler.transform(newTract), \n",
    "                               columns=['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'LSTAT'])\n",
    "\n",
    "newTractNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                    weights='uniform')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train knn model with k=3\n",
    "knn = KNeighborsRegressor(n_neighbors=3)\n",
    "knn.fit(train_X, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18.76666667])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict value of new tract\n",
    "knn.predict(newTractNorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted price of new tract is $18.77k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7.3.c.__ If we used the above k-NN algorithm to score the training data, what would be the error of the training set?\n",
    "\n",
    "__Answer__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the training set, the error is zero because the training cases are matched to themselves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7.3.d.__ Why is the validation data error overly optimistic compared to the error rate when applying this k-NN predictor to new data?\n",
    "\n",
    "__Answer__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation error measures the error for the \"best k\" among multiple k's tried out for the validation data, so that particular k is optimized for the particular validation data set that was used in selecting it. It may not be as suitable for the new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7.3.e.__ If the purpose is to predict MEDV for several thousands of new tracts, what would be the disadvantage of using k-NN prediction? List the operations that the algorithm goes through in order to produce each prediction.\n",
    "\n",
    "__Answer__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN does not yield a uniform rule that can be applied to each new record to be predicted -- the whole \"model building\" process has to be repeated for each new record to be classified.\n",
    "\n",
    "Specifically, the algorithm must calculate the distance from a new record to each of the training records, select the n-closest training records, determine the average target value for the n-closest training records, then score that target value to the new record, then repeat this process for each of the new records."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
